# Convolutional_Variational_Autoencoder

The purpose of this project is to implement a Convolutional Variational Autoencoder (CVAE) using TensorFlow and Keras to generate a generative model capable of learning and replicating the characteristic features present in a pool of complex data images. The under consideration dataset, defined on the ./dataset folder, is encoded into a lower-dimensional latent space and decoded to potentially reconstruct some of the original images. The model architecture has convolutional and fully connected layers that allow for efficient encoding and decoding. In training the Adam optimizer with the preset learning rate is used, and the model minimizes both reconstruction loss and Kullback-Leibler (KL) divergence in an iterative process. These metrics guarantee fidelity of the image generation is in accordance with the data distribution and the meaningful representation of the latent space.

Visualization of the training process involves plots with reconstruction loss and KL divergence curves observed over a number of epochs to give an idea of the model learning dynamics. Moreover, the project involves a stage of testing in which the trained model encodes and decodes a set of test images. The comparative display of the original and reconstructed images makes it possible to qualitatively assess the accuracy of movement of the model. This work intends to show the performance of CVAE in the extraction and construction of representations for complicated data, which can be used for image recovery, anomaly identification, and generative modeling. The remaining saved plots, “Loss_KL_Div. png” and “Image_Autoencoders. png,” represent short summaries of the training process and the ability of the model to produce images faithfully from the latent space.
